{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**End-to-end Machine Learning project**\n",
    "\n",
    "*Welcome to Machine Learning Housing Corp.!  \n",
    "Your task is to predict median house values in Californian districts, given a number of features from these districts.*\n",
    "\n",
    "This is a simplified version of a Jupyter notebook you can find on github under:  \n",
    "https://github.com/ageron/handson-ml/blob/master/02_end_to_end_machine_learning_project.ipynb\n",
    "\n",
    "**This notebook will NOT execute correctly, you will have to fill in the missing parts according to the description**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Ignore useless warnings (see SciPy issue #5998)\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data\n",
    "In the following section, we will read in the house pricing data and try to gain first insights.  \n",
    "Here are links to pandas methods which can be used for this:  \n",
    "\n",
    "* https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.info.html\n",
    "* https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.value_counts.html\n",
    "* https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html\n",
    "* https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.hist.html\n",
    "\n",
    "At first, try to show the [head](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.head.html\n",
    ") rows of the pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \".read_csv()\" reads csv files into so called pandas \"dataframes\"\n",
    "housing = pd.read_csv(\"datasets/housing/housing.csv\")\n",
    "\n",
    "# Try to get header information of the dataframe:\n",
    "housing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try to get some [informations](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.info.html) about the columns in the dataframe.  \n",
    "Question: Which of the columns are special?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now address the \"special\" column using it's name as index.  \n",
    "Then, [count](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.value_counts.html) the number of individual entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[\"special column\"]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a statistical [description](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html) of each column in housing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try to plot [histograms](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.hist.html) of the columns  \n",
    "Hint: there are parameters in the histogram method for formatting the plots, see e.g. `bins` or `figsize`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a histogram just of the `median_house_value` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discover and visualize the data to gain insights\n",
    "In the following, visualize the spacial (longitude, latitude) information of the dataset in a [scatter-plot](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.scatter.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to use the plot parameters s (size) and c (color) to add more information to the plot, like e.g. for the population or median house value.  \n",
    "--> more colourful is better ;-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.plot.\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the the [correlation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.corr.html) matrix of the housing dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the correlation matrix \n",
    "corr_matrix = housing.\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Sort](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sort_values.html) the correlations of the column `median_house_value` to find the highest correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_correlations = corr_matrix[]\n",
    "sorted_correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now plot a [scatter matrix](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.plotting.scatter_matrix.html) of the 4 highest correlating columns.  \n",
    "Hint for experts: use `sorted_correlations` and the series [index](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.index.html) to retrieve the names of the needed 4 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "attributes = \n",
    "scatter_matrix(housing[attributes], figsize=(12, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No try to make a scatter plot of the correlation between median_income and median_house value\n",
    "housing.plot.scatter(x=\"median_income\", y=\"median_house_value\", alpha=0.1)\n",
    "plt.axis([0, 16, 0, 550000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns total_rooms, total_bedrooms and population are not representative for individual houses  \n",
    "Try to define new colums which are related to the amount per household or total_rooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[\"rooms_per_household\"] = ...\n",
    "housing[\"bedrooms_per_room\"] = ...\n",
    "housing[\"population_per_household\"] = ...\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And calculate the correlation matrix and sort the column `median_house_value` again, now with the new columns.  \n",
    "What changed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = housing.corr()\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, make a [scatter plot](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.scatter.html) of the new column with the highest correlation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.plot.scatter(x = , y = , alpha=0.03)\n",
    "plt.axis([0, 20, 0, 520000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data for Machine Learning algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now separate labels from features:\n",
    "1. Create new dataset which just contains labels (\"median_house_value\") we want to train for\n",
    "2. Drop \"median_house_value\" from input data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_prep = housing.drop(\"median_house_value\", axis = 1).copy() # drop labels for training set\n",
    "housing_prep_labels = housing[\"median_house_value\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to find out where there is missing data before training a model.\n",
    "Use the methods [isnull()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.isnull.html) and [any()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.any.html) to find *any* rows where an entry *is null*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_incomplete_rows = housing_prep[ ]\n",
    "sample_incomplete_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many rows with missing data do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len( ... )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to deal with missing data ?\n",
    "There are several posibilities how to deal with missing data:\n",
    "1. Drop each row where data is missing / erroneous (see [dropna](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html) )\n",
    "2. Drop the colums where data is missing / erroneous (see [drop](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html))\n",
    "3. Replace the missing data with [mean](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.mean.html) or [median](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.median.html) of rows where data is available\n",
    "\n",
    "Choose an option in the cells below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1\n",
    "sample_incomplete_rows.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2\n",
    "sample_incomplete_rows.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 3\n",
    "median_tot_bedrooms = housing_prep[\"total_bedrooms\"].median()\n",
    "median_bedrooms_p_room = housing_prep[\"bedrooms_per_room\"].median()\n",
    "\n",
    "sample_incomplete_rows[\"total_bedrooms\"].fillna(median_tot_bedrooms, inplace=True)\n",
    "sample_incomplete_rows\n",
    "sample_incomplete_rows[\"bedrooms_per_room\"].fillna(median_bedrooms_p_room, inplace=True)\n",
    "sample_incomplete_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply one of the three options here, to pass the assertion below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "assert len(housing_prep[housing_prep.isnull().any(axis=1)]) == 0, \"Please make sure there are no more missing values!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to deal with categorical data?\n",
    "\n",
    "The column `ocean_proximity` is categorical.\n",
    "At first, check how much `unique` categories there are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_prep['ocean_proximity']."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Dummy variables](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html) could help here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_dummies = pd.get_dummies( ... )\n",
    "assert cat_dummies.shape[1] == 5\n",
    "cat_dummies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Concatenate](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html) cat_dummies with housing_prep\n",
    "and then drop the no more needed column `ocean_proximity`  \n",
    "The resulting concatenated dataframe `housing_prep2` should have 16 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_prep2 = pd.concat([housing_prep, cat_dummies], axis = 1).drop(columns=['ocean_proximity'])\n",
    "assert housing_prep2.shape[1] == 16\n",
    "housing_prep2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All columns in housing_prep2 are numerical now, lets [scale](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) them so they have similar distribution widths and means.  \n",
    "Be careful: `fit_transform` returns a numpy array, which must be converted to a dataframe before further usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing_scaled_arr = ...\n",
    "housing_scaled = pd.DataFrame(housing_scaled_arr, columns = ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select and train a model \n",
    "At first, [split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) `housing_scaled_arr` and `housing_prep_labels` in to train (`X_train`, `y_train`) and test (`X_test`, `y_test`) dataset.  \n",
    "Use `X_train` and `y_train` to train a model, then test it using `X_test` and `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train (`fit()`) a [linear regressor](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) on the training dataset `X_train` and `y_train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Instanciate a LinearRegression here and fit it using X_train and y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the model a few training instances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_data = X_train[:5]\n",
    "some_labels = y_train[:5]\n",
    "\n",
    "print(\"Predictions:\", lin_reg.predict(some_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare against the actual values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Labels:\", list(some_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, how good is the linear regression model?  \n",
    "A common metric is the root [mean square  error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html) between the values *predicted* by the model on the training features (X_train) and the actual labels (y_train).  \n",
    "Hint: to calculate the root of column elements, use e.g. [numpy sqrt](https://docs.scipy.org/doc/numpy/reference/generated/numpy.sqrt.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_pred = # Use linear regressor to predict y_pred based on X_train\n",
    "lin_mse = # Calculate mean square error between y_pred and y_train\n",
    "lin_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now calculate the same value for the test dataset X_test and y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = # Use linear regressor to predict y_pred based on X_test\n",
    "lin_mse = # Calculate mean square error between y_pred and y_test\n",
    "lin_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "lin_mae = # Do the same as above for the mean absolute error between y_pred and y_test\n",
    "lin_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now train a [DecisionTreeRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html) on X_train and y_train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Instanciate a DecisionTreeRegressor here and fit it using X_train and y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, compute the mean squared error between the predicted and training labels (y_train):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred =  # Use DecisionTreeRegressor to predict y_pred based on X_train\n",
    "tree_rmse = # Calculate mean square error between y_pred and y_train\n",
    "tree_rmse\n",
    "\n",
    "assert tree_rmse == 0.0 , 'this should be 0.0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the mean squared error between the predictions based on X_test and training labels (y_train):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred =  # Use DecisionTreeRegressor to predict y_pred based on X_test\n",
    "tree_rmse = # Calculate mean square error between y_pred and y_test\n",
    "tree_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:**\n",
    "* Why is the error 0.0 for the training set?\n",
    "* Why is there such a big difference in the errors?\n",
    "* How to improve the model?  \n",
    "\n",
    "Hints:\n",
    "* Try using the DecisionTreeRegressor options `max_depth`or `max_features`\n",
    "* Maybe a [RandomForestRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) could help..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional : Fine-tune your model\n",
    "Try to optimize your model\n",
    "If you think you are finished, [save](https://scikit-learn.org/stable/modules/model_persistence.html) your model to a file.  \n",
    "**The model with the best performance on a hidden validation dataset wins ;-)**  \n",
    "The model must take a the following columns as arguments:  \n",
    "\n",
    "'longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
    "       'total_bedrooms', 'population', 'households', 'median_income',\n",
    "       'rooms_per_household', 'bedrooms_per_room', 'population_per_household',\n",
    "       '<1H OCEAN', 'INLAND', 'ISLAND', 'NEAR BAY', 'NEAR OCEAN',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import getpass\n",
    "\n",
    "your_regressor = # Put your best regressor here\n",
    "\n",
    "pickle.dump(your_regressor, open(getpass.getuser() + \"s_model.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some additional code which can be used for optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(tree_reg, housing_prepared, housing_labels,\n",
    "                         scoring=\"neg_mean_squared_error\", cv=10)\n",
    "tree_rmse_scores = np.sqrt(-scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "display_scores(tree_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_scores = cross_val_score(lin_reg, housing_prepared, housing_labels,\n",
    "                             scoring=\"neg_mean_squared_error\", cv=10)\n",
    "lin_rmse_scores = np.sqrt(-lin_scores)\n",
    "display_scores(lin_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: we specify `n_estimators=10` to avoid a warning about the fact that the default value is going to change to 100 in Scikit-Learn 0.22."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest_reg = RandomForestRegressor(n_estimators=10, random_state=42)\n",
    "forest_reg.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_predictions = forest_reg.predict(housing_prepared)\n",
    "forest_mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "forest_rmse = np.sqrt(forest_mse)\n",
    "forest_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "forest_scores = cross_val_score(forest_reg, housing_prepared, housing_labels,\n",
    "                                scoring=\"neg_mean_squared_error\", cv=10)\n",
    "forest_rmse_scores = np.sqrt(-forest_scores)\n",
    "display_scores(forest_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(lin_reg, housing_prepared, housing_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "pd.Series(np.sqrt(-scores)).describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nav_menu": {
   "height": "279px",
   "width": "309px"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
